from Compiler import ml

def sigmoid(x):
    return x #  1/2 + x/4 - x**3/48 + x**5/480 - 17 * x**7/80640

def dot_product(a, b):
    assert (len(a) == len(b))

    res = sfix(0)
    for i in range(len(a)):
        res += a[i] * b[i]

    return res

# NOTE: This script should not be run alone. The entry point to run the program is in run.py.
#       run.py must be run first for the sake of some book-keeping; for example, run.py will
#       have Alice and Bob populate their private input files which allows for us to combine
#       their horizontally partitioned data into one dataset.

ALICE = 0
BOB = 1

# PURELY FOR TESTING PURPOSES - reduces the amount of data going in by a factor of n to test compilers
# ability to work with different loads
reduce_set = 2  # Anything lower than 49 does not work...

# It appears that batching is maxed out at 128
max_batch = 128

# No traditional command line arguments? Solution is to re-write the script
# using another python script which can also act as the entry point
# @args
alice_examples = 831
bob_examples = 882
n_features = 1875
n_epochs = 13
folds = 5
classify = True
# end@args

n_examples = alice_examples + bob_examples

print_ln("%s", folds)
print_ln("%s", n_examples)

data = Matrix(n_examples, n_features, sfix)

test_ratio = 1 / folds

# TODO: train_size should use ceil
train_size = int(n_examples * (1 - test_ratio))
test_size = int(n_examples * test_ratio)

print_ln("%s", train_size)
print_ln("%s", test_size)

# Load data from Alice first, then Bob

# Reference: self.X = MultiArray([N, d, d_in], sfix)
@for_range_opt(alice_examples)
def _(i):
    @for_range_opt(n_features)
    def _(j):
        data[i][j] = sfix.get_input_from(ALICE)
        # sgd.layers[0].X.input_from(ALICE)


print_ln("%s", "\n\n Alice's data is loaded \n\n")


@for_range_opt(bob_examples)
def _(i):
    @for_range_opt(n_features)
    def _(j):
        data[alice_examples + i][j] = sfix.get_input_from(BOB)
        # print_ln("i: %s, j: %s", i, j)
        # sgd.layers[0].X.input_from(BOB)


print_ln("%s", "\n\n Bobs data is loaded \n\n")

labels = Array(n_examples, sfix)


# Load labels from alice first to ensure that the labels remain parallel to the dataset
@for_range_opt(alice_examples)
def _(i):
    labels[i] = sfix.get_input_from(ALICE)
    # sgd.layers[1].Y.input_from(ALICE)


print_ln("%s", "\n\n Alice's labels is loaded \n\n")


@for_range_opt(bob_examples)
def _(i):
    labels[alice_examples + i] = sfix.get_input_from(BOB)
    # print_ln("i: %s", i)
    # sgd.layers[1].Y.input_from(BOB)


print_ln("%s", "\n\n Bobs labels is loaded \n\n")

@for_range(folds)
def _(f):

    global train_size

    print_ln("train size: %s", train_size)
    train_data = Matrix(train_size, n_features, sfix)
    train_label = Array(train_size, sfix)
    print_ln("train size: %s", train_size)

    test_data = Matrix(test_size, n_features, sfix)
    test_label = Array(test_size, sfix)

    # This does not change the folds at all, which is clearly not ideal; however, we can't use if statements in
    # the runtime-ready code, making this whole process somewhat difficult. This is in its current state just for
    # testing, will have to fix later TODO: actually partition dataset for corssfold validation
    @for_range_opt(test_size)
    def _(i):
        test_data[i] = data[i]
        test_label[i] = labels[i]

    @for_range_opt(train_size)
    def _(i):
        train_data[i] = data[i + test_size]
        train_label[i] = labels[i + test_size]

    # Define logistic regression model
    sgd = ml.SGD([ml.Dense(max_batch, n_features, 1),
                  ml.Output(n_examples, approx=True)], n_epochs,
                 report_loss=True)

    sgd.reset()  # <--- Can cause register overflow?

    print_ln("%s for fold %s", "\n\n model initialized \n\n", f)

    data_left_to_train = train_size

    print_ln("train size: %s", train_size)

    l_lt_r = data_left_to_train < max_batch
    # Although these are all public values, the compiler complained about not being able to determine the truth
    # value of the expression "data_left_to_train < max_batch". TODO: Make this cleaner for clear values
    batch_size = data_left_to_train * (l_lt_r) + max_batch * (1 - l_lt_r)

    print_ln("batch size: %s", batch_size)
    print_ln("feature size: %s", n_features)

    print_ln("Shape of input: %s", sgd.layers[0].X.reveal())
    print_ln("Shape of output: %s", sgd.layers[1].Y.reveal())

    # write training params
    @for_range_opt(batch_size)
    def _(i):
        # print_ln("iteration: %s", i)
        @for_range_opt(n_features)
        def _(j):
            # print_ln("iteration: %s", j)
            sgd.layers[0].X[i][0][j] = train_data[i][j]
        sgd.layers[1].Y[i] = train_label[i]

    print_ln("\t performing training for batch %s", 0)

    sgd.run()

    data_left_to_train -= max_batch

    print_ln("\t data left in batch: %s", data_left_to_train)

    current_batch = 1

    while data_left_to_train > 0:

        l_lt_r = data_left_to_train < max_batch
        # Although these are all public values, the compiler complained about not being able to determine the truth
        # value of the expression "data_left_to_train < max_batch". TODO: Make this cleaner for clear values
        batch_size = data_left_to_train * (l_lt_r) + max_batch * (1 - l_lt_r)

        # write training params
        @for_range_opt(batch_size)
        def _(i):
            # print_ln("iteration: %s", i)
            @for_range_opt(n_features)
            def _(j):
                # print_ln("iteration: %s", j)
                sgd.layers[0].X[i][0][j] = train_data[i + current_batch * max_batch][j]
            sgd.layers[1].Y[i] = train_label[i]

        print_ln("\t performing training for batch %s", current_batch)
        print_ln("\t performing training for batch %s", current_batch)
        sgd.run()

        data_left_to_train -= max_batch
        current_batch += 1




    # @for_range_opt(max_batch)
    # def _(i):
    #     # print_ln("iteration: %s", i)
    #     @for_range_opt(n_features)
    #     def _(j):
    #         # print_ln("iteration: %s", j)
    #         sgd.layers[0].X[i][0][j] = data[i][j]
    #     sgd.layers[1].Y[i] = labels[i]
    #
    # sgd.run()
    # print_ln("%s", sgd.layers[0].W)

    weights = sgd.layers[0].W
    bias = 0  # Compiler says this does not exist despite it being in the documentation... sgd.layers[1].b

    #print(weights)

    print_ln("%s", weights)

    # if classify:
    #
    #     predictions = Array(test_size, sfix)
    #     threshold = sfix(0.5)
    #
    #     @for_range_opt(test_size)
    #     def _(i):
    #         predictions[i] = sigmoid(dot_product(test_data[i], weights) + bias)
    #         predictions[i] = predictions[i] >= threshold
    #
    #     correct = sint(0)
    #     incorrect = sint(0)
    #
    #     @for_range_opt(test_size)
    #     def _(i):
    #         res = predictions[i] == test_label[i]
    #
    #         correct += res
    #         incorrect += 1 - res
    #
    #     correct = correct.reveal()
    #     incorrect = incorrect.reveal()
    #
    #     # ratio = correct / (correct + incorrect)
    #
    #     print_ln("ratio: %s, correct: %s, incorrect: %s", 0, correct, incorrect)

        # sgd.layers[0].X.input_from(0)
        # sgd.layers[1].Y.input_from(1)
